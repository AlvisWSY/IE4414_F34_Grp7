{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T14:34:37.454322Z","iopub.status.busy":"2024-04-14T14:34:37.453758Z","iopub.status.idle":"2024-04-14T14:34:48.756524Z","shell.execute_reply":"2024-04-14T14:34:48.755547Z","shell.execute_reply.started":"2024-04-14T14:34:37.454293Z"},"trusted":true},"outputs":[],"source":["#base libraries for filemanagement etc\n","import os\n","import glob\n","from tqdm import tqdm\n","import random\n","import tarfile\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","#data handling and visualiation libaries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","\n","#image aug libraries\n","from PIL import Image #using library pillow\n","\n","#pytorch libraries\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import DataLoader,Dataset,WeightedRandomSampler,random_split\n","from torch.optim import Adam\n","from torch.autograd import Variable\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from torchvision.datasets.utils import download_url\n","from torchvision.datasets import ImageFolder\n","from torchvision.utils import make_grid\n","\n","import torchmetrics\n","import torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:44:26.888390Z","iopub.status.busy":"2024-04-14T14:44:26.887468Z","iopub.status.idle":"2024-04-14T14:44:26.993864Z","shell.execute_reply":"2024-04-14T14:44:26.992968Z","shell.execute_reply.started":"2024-04-14T14:44:26.888356Z"},"trusted":true},"outputs":[],"source":["from __future__ import print_function, division\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","import torchvision.transforms.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset\n","import numpy as np\n","import torchvision\n","from torchvision import models, transforms\n","from torchvision.datasets.folder import make_dataset\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report\n","\n","%matplotlib inline\n","plt.ion()   # interactive mode"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:35:16.016861Z","iopub.status.busy":"2024-04-14T14:35:16.015696Z","iopub.status.idle":"2024-04-14T14:35:29.359102Z","shell.execute_reply":"2024-04-14T14:35:29.357821Z","shell.execute_reply.started":"2024-04-14T14:35:16.016828Z"},"trusted":true},"outputs":[],"source":["pip install torchsummary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:35:29.362050Z","iopub.status.busy":"2024-04-14T14:35:29.361669Z","iopub.status.idle":"2024-04-14T14:35:29.371524Z","shell.execute_reply":"2024-04-14T14:35:29.370775Z","shell.execute_reply.started":"2024-04-14T14:35:29.362008Z"},"trusted":true},"outputs":[],"source":["from torchsummary import summary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:35:29.373565Z","iopub.status.busy":"2024-04-14T14:35:29.372760Z","iopub.status.idle":"2024-04-14T14:35:29.386181Z","shell.execute_reply":"2024-04-14T14:35:29.385250Z","shell.execute_reply.started":"2024-04-14T14:35:29.373535Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:35:29.388484Z","iopub.status.busy":"2024-04-14T14:35:29.388156Z","iopub.status.idle":"2024-04-14T14:35:29.430528Z","shell.execute_reply":"2024-04-14T14:35:29.429573Z","shell.execute_reply.started":"2024-04-14T14:35:29.388449Z"},"trusted":true},"outputs":[],"source":["# use cuda if it is available else use cpu, cuda can handle more data and does training faster\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:35:29.432365Z","iopub.status.busy":"2024-04-14T14:35:29.431978Z","iopub.status.idle":"2024-04-14T14:35:29.441232Z","shell.execute_reply":"2024-04-14T14:35:29.440403Z","shell.execute_reply.started":"2024-04-14T14:35:29.432307Z"},"trusted":true},"outputs":[],"source":["RANDOM_SEED = 115\n","torch.cuda.manual_seed(RANDOM_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:35:29.442584Z","iopub.status.busy":"2024-04-14T14:35:29.442306Z","iopub.status.idle":"2024-04-14T14:35:29.448832Z","shell.execute_reply":"2024-04-14T14:35:29.448082Z","shell.execute_reply.started":"2024-04-14T14:35:29.442560Z"},"trusted":true},"outputs":[],"source":["img_dims = 224\n","target_size = (img_dims, img_dims) # size of dataset images\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:35:29.460976Z","iopub.status.busy":"2024-04-14T14:35:29.460728Z","iopub.status.idle":"2024-04-14T14:35:29.473819Z","shell.execute_reply":"2024-04-14T14:35:29.473035Z","shell.execute_reply.started":"2024-04-14T14:35:29.460955Z"},"trusted":true},"outputs":[],"source":["# Define the dataset class\n","class sg_food_dataset(torch.utils.data.dataset.Dataset):\n","    def __init__(self, root, class_id, transform=None):\n","        self.class_id = class_id\n","        self.root = root\n","        all_classes = sorted(entry.name for entry in os.scandir(root) if entry.is_dir())\n","        if not all_classes:\n","            raise FileNotFoundError(f\"Couldn't find any class folder in {directory}.\")\n","        self.classes = [all_classes[x] for x in class_id]\n","        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n","\n","        self.samples = make_dataset(self.root, self.class_to_idx, extensions=('jpg'))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        path, target = self.samples[idx]\n","        with open(path, \"rb\") as f:\n","            sample = Image.open(f).convert('RGB')\n","        if self.transform is not None:\n","            sample = self.transform(sample)\n","        return sample, target"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:15:25.145691Z","iopub.status.busy":"2024-04-14T17:15:25.145180Z","iopub.status.idle":"2024-04-14T17:15:25.155386Z","shell.execute_reply":"2024-04-14T17:15:25.154410Z","shell.execute_reply.started":"2024-04-14T17:15:25.145657Z"},"trusted":true},"outputs":[],"source":["# Data augmentation and normalization for training\n","data_transforms = {\n","    'train': transforms.Compose([\n","        # Define data preparation operations for training set here.\n","        # Tips: Use torchvision.transforms\n","        #       https://pytorch.org/vision/stable/transforms.html\n","        #       Normally this should at least contain resizing (Resize) and data format converting (ToTensor).\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),     \n","        transforms.RandomVerticalFlip(),\n","        transforms.ColorJitter(brightness=0.1, contrast=0.1 , saturation = 0.1), #random brightness, contrast etc\n","\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet prior\n","    ]),\n","    'val': transforms.Compose([\n","        # Define data preparation operations for testing/validation set here.\n","        transforms.Resize((256,256), antialias=True),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet prior\n","    ]),\n","    'test': transforms.Compose([\n","        # Define data preparation operations for testing/validation set here.\n","        transforms.Resize((256,256), antialias=True),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet prior\n","    ]),\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:15:27.441074Z","iopub.status.busy":"2024-04-14T17:15:27.440444Z","iopub.status.idle":"2024-04-14T17:15:27.805276Z","shell.execute_reply":"2024-04-14T17:15:27.804362Z","shell.execute_reply.started":"2024-04-14T17:15:27.441038Z"},"trusted":true},"outputs":[],"source":["data_dir = '/kaggle/input/sg-food/sg_food' \n","subfolder = {'train': 'train', 'val': 'val', 'test': 'test'}\n","\n","# Define the dataset\n","selected_classes = [0, 2, 4, 7, 9]\n","n_classes = len(selected_classes)\n","image_datasets = {x: sg_food_dataset(root=os.path.join(data_dir, subfolder[x]),\n","                                     class_id=selected_classes,\n","                                     transform=data_transforms[x]) \n","                  for x in ['train', 'val','test']}\n","class_names = image_datasets['train'].classes\n","print('selected classes:\\n    id: {}\\n    name: {}'.format(selected_classes, class_names))\n","\n","# Define the dataloader\n","batch_size = 16\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n","                                             shuffle=True, num_workers=0)\n","              for x in ['train', 'val','test']}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["# Visualise dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:46:54.826809Z","iopub.status.busy":"2024-04-14T14:46:54.825818Z","iopub.status.idle":"2024-04-14T14:46:55.249362Z","shell.execute_reply":"2024-04-14T14:46:55.248334Z","shell.execute_reply.started":"2024-04-14T14:46:54.826759Z"},"trusted":true},"outputs":[],"source":["def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","# Get a batch of training data\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# Make a grid from batch\n","out = torchvision.utils.make_grid(inputs[:4])\n","\n","imshow(out, title=[class_names[x] for x in classes[:4]])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:15:57.130629Z","iopub.status.busy":"2024-04-14T17:15:57.130224Z","iopub.status.idle":"2024-04-14T17:15:57.135643Z","shell.execute_reply":"2024-04-14T17:15:57.134701Z","shell.execute_reply.started":"2024-04-14T17:15:57.130595Z"},"trusted":true},"outputs":[],"source":["train_loader = dataloaders['train']\n","val_loader = dataloaders['val']\n","test_loader = dataloaders['test']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:12:56.662405Z","iopub.status.busy":"2024-04-14T17:12:56.662029Z","iopub.status.idle":"2024-04-14T17:12:56.675766Z","shell.execute_reply":"2024-04-14T17:12:56.674936Z","shell.execute_reply.started":"2024-04-14T17:12:56.662376Z"},"trusted":true},"outputs":[],"source":["# Labels\n","def get_model_results(model, data_loader):\n","    loop = tqdm(data_loader, total=len(data_loader))\n","\n","    y_preds = []\n","    y_trues = []\n","    \n","    # Assuming device is defined elsewhere in your code\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    \n","    with torch.inference_mode():\n","        model.eval()\n","        for X, y_true in loop:\n","            X = X.to(device)\n","            y_true = y_true.to(device)\n","            \n","            y_pred = model(X)\n","            _, y_pred_class = torch.max(y_pred, 1)\n","\n","            y_preds.extend(y_pred_class.data.cpu().numpy())\n","            y_trues.extend(y_true.data.cpu().numpy())\n","\n","    print(f\"{len(data_loader.dataset)} images\")\n","    return y_preds, y_trues\n","from sklearn.metrics import confusion_matrix,roc_auc_score,accuracy_score,f1_score\n","\n","def print_classification_report(y_trues,y_preds,dataset_name=''):\n","    print(f'Classification Report: {dataset_name}')\n","    # Build confusion matrix\n","    cf_matrix = confusion_matrix(y_trues, y_preds)\n","    df_cm = pd.DataFrame(cf_matrix, index = [i for i in selected_classes],\n","                         columns = [i for i in selected_classes])\n","    plt.figure(figsize = (12,7))\n","    sns.heatmap(df_cm, annot=True,fmt='g')\n","\n","    # Set the axis labels and title\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    \n","    print('Accuracy: ', accuracy_score(y_trues,y_preds))\n","    print('F1 Score: ', f1_score(y_trues,y_preds,average='macro'))\n","    \n","    \n","    plt.show()\n","    plt.savefig(f\"{dataset_name} Confusion Matrix.jpg\", dpi=600)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Knowledge Distillation training"]},{"cell_type":"markdown","metadata":{},"source":["### Define Teacher Vision Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T14:46:55.602659Z","iopub.status.busy":"2024-04-14T14:46:55.601919Z","iopub.status.idle":"2024-04-14T14:46:55.611365Z","shell.execute_reply":"2024-04-14T14:46:55.610388Z","shell.execute_reply.started":"2024-04-14T14:46:55.602625Z"},"trusted":true},"outputs":[],"source":["from transformers import ViTModel\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Define the model\n","class ViTForImageClassification(nn.Module):\n","    def __init__(self, num_labels, other_argument=None):\n","        super(ViTForImageClassification, self).__init__()\n","        # Your model initialization code here\n","        # Example:\n","        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n","        self.num_labels = num_labels\n","\n","    def forward(self, pixel_values, labels=None):\n","        # Your forward pass code here\n","        # Example:\n","        outputs = self.vit(pixel_values=pixel_values)\n","        output = self.dropout(outputs.last_hidden_state[:, 0])\n","        logits = self.classifier(output)\n","\n","        if labels is not None:\n","            # Calculate loss\n","            loss_fct = nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n","            return loss\n","        else:\n","            return logits"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# initialize teacher and student"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:33:27.446348Z","iopub.status.busy":"2024-04-14T16:33:27.445961Z","iopub.status.idle":"2024-04-14T16:33:28.047031Z","shell.execute_reply":"2024-04-14T16:33:28.046158Z","shell.execute_reply.started":"2024-04-14T16:33:27.446317Z"},"trusted":true},"outputs":[],"source":["# Instantiate the Vision Transformer model as the teacher model\n","teacher_type = \"VisionTransformer\"\n","teacher_model = ViTForImageClassification(5) # 5 classes\n","\n","teacher_model = torch.load('/kaggle/input/4414visiontransformer/model_ViT.pt')\n","teacher_model.classifier = nn.Linear(in_features=768, out_features=5, bias=True)\n","teacher_model = teacher_model.to(device)\n","teacher_model.eval()\n","teacher_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:04:39.410892Z","iopub.status.busy":"2024-04-14T17:04:39.410246Z","iopub.status.idle":"2024-04-14T17:04:39.667729Z","shell.execute_reply":"2024-04-14T17:04:39.666821Z","shell.execute_reply.started":"2024-04-14T17:04:39.410858Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Instantiate the student model\n","student_type = \"Resnet18\"\n","student_model = models.resnet18(pretrained=True)\n","\n","# change the final layer of ResNet Model for Transfer Learning\n","fc_inputs = student_model.fc.in_features\n","student_model.fc = nn.Sequential(nn.Linear(fc_inputs, 5)) # change no. of classes\n","student_model = student_model.to(device)\n","summary(student_model, input_size = (3,224,224))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:04:39.670288Z","iopub.status.busy":"2024-04-14T17:04:39.669638Z","iopub.status.idle":"2024-04-14T17:04:40.288239Z","shell.execute_reply":"2024-04-14T17:04:40.287262Z","shell.execute_reply.started":"2024-04-14T17:04:39.670250Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()\n","import gc\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# training prep"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:04:40.290155Z","iopub.status.busy":"2024-04-14T17:04:40.289808Z","iopub.status.idle":"2024-04-14T17:04:40.301355Z","shell.execute_reply":"2024-04-14T17:04:40.300609Z","shell.execute_reply.started":"2024-04-14T17:04:40.290122Z"},"trusted":true},"outputs":[],"source":["def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","def validation_step(model, batch):\n","    images, labels = batch \n","    images, labels = images.to(device), labels.to(device)\n","    teacher_pred = teacher_model(images)                  # Generate predictions\n","    out = model(images) \n","    loss = 0.5*(distillation_loss(out, teacher_pred, temperature)) + 0.5*(criterion(out, labels))   # Calculate loss\n","    acc = accuracy(out, labels)           # Calculate accuracy\n","    return {'val_loss': loss.detach(), 'val_acc': acc}\n","\n","def validation_epoch_end(outputs):\n","    batch_losses = [x['val_loss'] for x in outputs]\n","    epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","    batch_accs = [x['val_acc'] for x in outputs]\n","    epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","\n","def epoch_end(epoch, result):\n","    print(\"Epoch [{}], last_lr: {:.8f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","        epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n","    if result['val_acc']>0.93:\n","        torch.save(student_model.state_dict(), f'{student_type}-student_of_{teacher_type}_{temperature}_acc93.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:04:40.315370Z","iopub.status.busy":"2024-04-14T17:04:40.315107Z","iopub.status.idle":"2024-04-14T17:04:40.320386Z","shell.execute_reply":"2024-04-14T17:04:40.319456Z","shell.execute_reply.started":"2024-04-14T17:04:40.315345Z"},"trusted":true},"outputs":[],"source":["# Define the distillation loss function\n","def distillation_loss(student_outputs, teacher_outputs, temperature):\n","    soft_teacher_outputs = F.softmax(teacher_outputs / temperature, dim=1)\n","    soft_student_outputs = F.log_softmax(student_outputs / temperature, dim=1)\n","    return F.kl_div(soft_student_outputs, soft_teacher_outputs, reduction='batchmean')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:04:40.521307Z","iopub.status.busy":"2024-04-14T17:04:40.520423Z","iopub.status.idle":"2024-04-14T17:04:40.535322Z","shell.execute_reply":"2024-04-14T17:04:40.534313Z","shell.execute_reply.started":"2024-04-14T17:04:40.521270Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [validation_step(model,batch) for batch in val_loader]\n","    return validation_epoch_end(outputs)\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","def fit_one_cycle(epochs, max_lr,temperature, teacher_model, student_model, train_loader, val_loader, \n","                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD, criterion = nn.CrossEntropyLoss()):\n","    torch.cuda.empty_cache()\n","    history = []\n","    \n","    # Set up cutom optimizer with weight decay\n","    optimizer = opt_func(student_model.parameters(), max_lr)#, weight_decay=weight_decay)\n","                        # optimizer for student\n","    \n","    # Set up one-cycle learning rate scheduler\n","    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n","                                                steps_per_epoch=len(train_loader))\n","    \n","    for epoch in tqdm(range(epochs)):\n","        # Training Phase \n","        teacher_model.eval()\n","        student_model.train()\n","        \n","        cls_losses = []\n","        div_losses = []\n","        losses = []\n","        lrs = []\n","        for batch in train_loader:\n","            teacher_model.eval()\n","            images, labels = batch \n","            images, labels = images.to(device), labels.to(device)\n","            \n","            teacher_pred = teacher_model(images)                  # Generate predictions\n","            cls_pred = student_model(images)                  # Generate predictions\n","            \n","            \n","#             # Gradient clipping\n","#             if grad_clip: \n","#                 nn.utils.clip_grad_value_(student_model.parameters(), grad_clip)\n","\n","            cls_loss = criterion(cls_pred, labels) # Calculate loss\n","            div_loss = distillation_loss(cls_pred, teacher_pred, temperature)\n","            \n","            \n","            cls_losses.append(cls_loss)\n","            div_losses.append(div_loss)\n","            \n","            loss = 0.5 * cls_loss + 0.5 * div_loss\n","            \n","            losses.append(loss)\n","            loss.backward()\n","            \n","            optimizer.step()\n","            optimizer.zero_grad()\n","            \n","            # Record & update learning rate\n","            lrs.append(get_lr(optimizer))\n","            sched.step()\n","        \n","        # Validation phase\n","        result = evaluate(student_model, val_loader)\n","        \n","        result['div_loss'] = torch.stack(div_losses).mean().item()\n","        result['cls_loss'] = torch.stack(cls_losses).mean().item()\n","        \n","        result['train_loss'] = torch.stack(losses).mean().item()\n","        result['lrs'] = lrs\n","        \n","        epoch_end(epoch, result)\n","        history.append(result)\n","    return history"]},{"cell_type":"markdown","metadata":{},"source":["# train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:04:41.023468Z","iopub.status.busy":"2024-04-14T17:04:41.022738Z","iopub.status.idle":"2024-04-14T17:04:41.028150Z","shell.execute_reply":"2024-04-14T17:04:41.027242Z","shell.execute_reply.started":"2024-04-14T17:04:41.023409Z"},"trusted":true},"outputs":[],"source":["epochs = 20\n","max_lr = 1e-4\n","grad_clip = 0\n","weight_decay = 5e-4\n","opt_func = torch.optim.Adam\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:04:41.399760Z","iopub.status.busy":"2024-04-14T17:04:41.399049Z","iopub.status.idle":"2024-04-14T17:08:36.324695Z","shell.execute_reply":"2024-04-14T17:08:36.323789Z","shell.execute_reply.started":"2024-04-14T17:04:41.399720Z"},"trusted":true},"outputs":[],"source":["%%time\n","temperature = 3 # Temperature parameter for distillation\n","history = fit_one_cycle(epochs, max_lr,temperature, teacher_model,student_model, train_loader, val_loader, \n","                             grad_clip=grad_clip, \n","                             weight_decay=weight_decay, \n","                             opt_func=opt_func)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:09:18.705415Z","iopub.status.busy":"2024-04-14T17:09:18.705041Z","iopub.status.idle":"2024-04-14T17:09:18.781258Z","shell.execute_reply":"2024-04-14T17:09:18.780476Z","shell.execute_reply.started":"2024-04-14T17:09:18.705385Z"},"trusted":true},"outputs":[],"source":["torch.save(student_model.state_dict(), f'{student_type}-student_of_{teacher_type}_{temperature}_9125.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:10:09.244367Z","iopub.status.busy":"2024-04-14T17:10:09.243985Z","iopub.status.idle":"2024-04-14T17:10:09.253339Z","shell.execute_reply":"2024-04-14T17:10:09.252393Z","shell.execute_reply.started":"2024-04-14T17:10:09.244337Z"},"trusted":true},"outputs":[],"source":["def plot_accuracies(history):\n","    accuracies = [x['val_acc'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs');\n","    \n","def plot_losses(history):\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, '-bx')\n","    plt.plot(val_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation'])\n","    plt.title('Loss vs. No. of epochs');\n","    \n","def plot_lrs(history):\n","    lrs = np.concatenate([x.get('lrs', []) for x in history])\n","    plt.plot(lrs)\n","    plt.xlabel('Batch no.')\n","    plt.ylabel('Learning rate')\n","    plt.title('Learning Rate vs. Batch no.');"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:10:10.035260Z","iopub.status.busy":"2024-04-14T17:10:10.034541Z","iopub.status.idle":"2024-04-14T17:10:10.342938Z","shell.execute_reply":"2024-04-14T17:10:10.341919Z","shell.execute_reply.started":"2024-04-14T17:10:10.035229Z"},"trusted":true},"outputs":[],"source":["plot_accuracies(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:10:10.696139Z","iopub.status.busy":"2024-04-14T17:10:10.695655Z","iopub.status.idle":"2024-04-14T17:10:11.029843Z","shell.execute_reply":"2024-04-14T17:10:11.028870Z","shell.execute_reply.started":"2024-04-14T17:10:10.696102Z"},"trusted":true},"outputs":[],"source":["plot_losses(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:10:21.145000Z","iopub.status.busy":"2024-04-14T17:10:21.144148Z","iopub.status.idle":"2024-04-14T17:10:21.383649Z","shell.execute_reply":"2024-04-14T17:10:21.382805Z","shell.execute_reply.started":"2024-04-14T17:10:21.144964Z"},"trusted":true},"outputs":[],"source":["plot_lrs(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:11:01.600555Z","iopub.status.busy":"2024-04-14T17:11:01.599616Z","iopub.status.idle":"2024-04-14T17:11:01.988126Z","shell.execute_reply":"2024-04-14T17:11:01.987208Z","shell.execute_reply.started":"2024-04-14T17:11:01.600520Z"},"trusted":true},"outputs":[],"source":["def plot_losses(history):\n","    cls_losses = [x.get('cls_loss') for x in history]\n","    div_losses = [x.get('div_loss') for x in history]\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, 'k')\n","    plt.plot(val_losses, 'm')\n","    \n","    plt.plot(cls_losses, '-bx')\n","    plt.plot(div_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation', 'Class Loss','Div Loss'])\n","    plt.title('Loss vs. No. of epochs')\n","    \n","plot_losses(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:13:00.559767Z","iopub.status.busy":"2024-04-14T17:13:00.559361Z","iopub.status.idle":"2024-04-14T17:13:04.933595Z","shell.execute_reply":"2024-04-14T17:13:04.932603Z","shell.execute_reply.started":"2024-04-14T17:13:00.559735Z"},"trusted":true},"outputs":[],"source":["%%time\n","t_preds, t_trues = get_model_results(student_model,train_loader)\n","print_classification_report(t_trues,t_preds,'Train Dataset')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:13:09.474354Z","iopub.status.busy":"2024-04-14T17:13:09.473957Z","iopub.status.idle":"2024-04-14T17:13:10.731966Z","shell.execute_reply":"2024-04-14T17:13:10.730996Z","shell.execute_reply.started":"2024-04-14T17:13:09.474322Z"},"trusted":true},"outputs":[],"source":["%%time\n","val_preds, val_trues = get_model_results(student_model,val_loader)\n","print_classification_report(val_trues,val_preds,'Validation Dataset')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:16:16.047137Z","iopub.status.busy":"2024-04-14T17:16:16.046266Z","iopub.status.idle":"2024-04-14T17:16:26.672624Z","shell.execute_reply":"2024-04-14T17:16:26.671753Z","shell.execute_reply.started":"2024-04-14T17:16:16.047102Z"},"trusted":true},"outputs":[],"source":["%%time\n","test_preds, test_trues = get_model_results(student_model,test_loader)\n","print_classification_report(test_trues,test_preds,'Test Dataset')"]},{"cell_type":"markdown","metadata":{},"source":["# Test classifier with 93.12% val acc during training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:20:16.437201Z","iopub.status.busy":"2024-04-14T17:20:16.436834Z","iopub.status.idle":"2024-04-14T17:20:16.774790Z","shell.execute_reply":"2024-04-14T17:20:16.773680Z","shell.execute_reply.started":"2024-04-14T17:20:16.437173Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Instantiate the student model\n","student_type = \"Resnet18\"\n","student_model1 = models.resnet18(pretrained=True)\n","\n","# change the final layer of ResNet Model for Transfer Learning\n","fc_inputs = student_model1.fc.in_features\n","student_model1.fc = nn.Sequential(nn.Linear(fc_inputs, 5)) # change no. of classes\n","\n","student_model1.load_state_dict(torch.load('/kaggle/working/Resnet18-student_of_VisionTransformer_3_93-12percent.pth'))\n","student_model1 = student_model1.to(device)\n","student_model1.eval()\n","summary(student_model1, input_size = (3,224,224))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:20:17.355788Z","iopub.status.busy":"2024-04-14T17:20:17.354917Z","iopub.status.idle":"2024-04-14T17:20:22.536111Z","shell.execute_reply":"2024-04-14T17:20:22.535136Z","shell.execute_reply.started":"2024-04-14T17:20:17.355753Z"},"trusted":true},"outputs":[],"source":["%%time\n","t_preds, t_trues = get_model_results(student_model1,train_loader)\n","print_classification_report(t_trues,t_preds,'Train Dataset')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:20:22.538626Z","iopub.status.busy":"2024-04-14T17:20:22.537949Z","iopub.status.idle":"2024-04-14T17:20:23.781300Z","shell.execute_reply":"2024-04-14T17:20:23.780376Z","shell.execute_reply.started":"2024-04-14T17:20:22.538590Z"},"trusted":true},"outputs":[],"source":["%%time\n","val_preds, val_trues = get_model_results(student_model1,val_loader)\n","print_classification_report(val_trues,val_preds,'Validation Dataset')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T17:20:23.782959Z","iopub.status.busy":"2024-04-14T17:20:23.782596Z","iopub.status.idle":"2024-04-14T17:20:29.790649Z","shell.execute_reply":"2024-04-14T17:20:29.789513Z","shell.execute_reply.started":"2024-04-14T17:20:23.782930Z"},"trusted":true},"outputs":[],"source":["%%time\n","test_preds, test_trues = get_model_results(student_model1,test_loader)\n","print_classification_report(test_trues,test_preds,'Test Dataset')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4707001,"sourceId":7994861,"sourceType":"datasetVersion"},{"datasetId":4795884,"sourceId":8117145,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
